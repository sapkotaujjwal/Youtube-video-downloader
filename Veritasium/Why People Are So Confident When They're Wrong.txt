Title: Why People Are So Confident When They're Wrong
URL: https://www.youtube.com/watch?v=9M_QK4stCJU

WEBVTT Kind: captions Language: en - [Derek] Friday, the 17th of July, 1992. Amidst the chaos of the trading floor at Singapore's international stock exchange, one of the junior traders makes an expensive mistake. Instead of buying 20 futures contracts for a client, she sold them instead, costing Barings Bank nearly $40,000. To save her job, Her boss, Nick Leeson, a young trader keen to make his mark, decides to hide the loss. He puts it in an obscure error account, that's account 88888. It's used by banks to solve small discrepancies and trades. It's a dangerous move and it should have been picked up by the central office immediately, but when nobody from Barings notices, he gains confidence, convinced he can win back the loss and get the team out of trouble. - I'm operating in the belief that I can get it back. You know, maybe it goes back to the confidence thing. I don't know. I mean, I'm confident I can get it back at that stage. - But Leeson's staggering overconfidence would create a debt of gargantuan proportions and lead to one of the biggest collapses in banking history. - It's easy for me to make the case at overconfidence as the most dangerous of the human biases. Overconfidence gets us into all sorts of trouble. It leads us to take risks, make commitments, enter contests, try things that will ultimately fail, sometimes in costly, embarrassing, and dangerous ways. - Overconfidence has been implicated in almost every big disaster, from the sinking of the Titanic to the Chernobyl nuclear disaster, to the loss of the space shuttle Challenger. But overconfidence isn't reserved for just a few reckless individuals. We can all fall victim to it. For example, 93% of us think we are better drivers than the median, which is, of course, impossible. The scale of the problem was identified in some now-classic research with a set of simple quiz questions. True or false, Australia is wider than the moon. - Oh! I bet they're about the same size. - It looks small on a map, but it's huge. - Are there more or less stars in the Milky Way than trees on Earth? - More stars. - Than trees? - More stars. - One teaspoon of pure olive oil, - Right. - Four and a half grams, contains more chemical potential energy than an equivalent four and a half gram amount of TNT. - I'm gonna say true. - Hmm. Oh no. (Derek laughs) - This feels kind of like a trick question. - The energy density of butter is 10 times that of lithium batteries, right? I mean, lithium batteries are rubbish. Everyone's going on about them. (Derek laughs) Just run your car on butter, I say. - True or false, plants are more efficient than the average solar panel at absorbing the sun's energy. - Yeah. - They must be. - Now, these aren't the exact questions from the original research, more on those later, but the specifics don't really matter. The interesting bit is what they asked next, how confident are you that you are right? - 100% confident. (interviewee speaks faintly) - 100% confident? - 100, yes. - I think it's true. So, I've also gotta go 90%. - 100%. - 100%. - 100%? - Yeah. - I don't think we actually had any expectations. This was very early on in the research on confidence assessment, but we didn't really know what we would find. - The results revealed a surprising disparity between how accurate someone thinks they are and how accurate they actually are. When people are 90% certain, they are right, only 75% of the time. In fact, we ran our own version of this online and found an even more extreme discrepancy. We asked the Veritasium community a bunch of science questions and then asked how confident they were in their answer. Our results showed that those who were the most confident describing themselves as 91 to 100% sure were only correct 51% of the time. Since the original research, these results have been replicated again and again in all areas from general knowledge to motor skills, and it affects everyone, even experts. - I have a paper where we analyze the survey of professional forecasters. These are chief economists at various corporations and banks who are invited to forecast the state of the economy on a quarterly basis. We find that they are, on average, too sure that they know what's going to happen, so they, on average, say there's something like 53% sure they have correctly predicted what's gonna happen to inflation, for instance, and they are right, like, 23% of the time. - How well what you think you know matches with what you actually know is called your calibration. So, if you're perfectly calibrated and, say, 80% confident, you should be right 80% of the time, but most of us are not well calibrated. 100% - 100%? - Yeah. - There are 200 billion stars in the Milky Way, but there are 3 trillion trees on Earth. - [Group] Oh! (interviewee groans) - 100% confident? - 100, yes. False! (laughs) (interviewee mimics mocking tune) (group laughs) - Most of the time, being overconfident isn't a huge issue, but for Nick Leeson, the stakes soon became very high. Leeson's plan to recover his team's loss was to bet that the Japanese stock market would go up, so he went long on the top 225 companies in Japan, the Nikkei 225. Ever since the Japanese asset price bubble peaked two years previously, the Nikkei had been dropping from 38,000 to 16,000, and he was confident the market would soon bottom out and start rising, but it continued to fall. Over the next few weeks, it dropped to a low of 14,000, and the whole time, Nick was betting the wrong way with ever bigger and riskier bets, he would double down, betting double his losses, so the next win would bring him back above water. This strategy should work when the next win comes along, but the market collapse was unrelenting, and his losses ballooned from $40,000 to around $3 million. In spite of this, Leeson remained confident, and eventually, his luck turned around. In the spring of 1993, the market rebounded up to 20,000, and by the summer, that account was back in credit. Leeson goes out to celebrate that weekend, drinking and dancing on tables, finally free of the hole he had dug himself into. But on Monday morning, he made another trading error on the futures market, a damaging loss that Leeson didn't want to admit, so he put the loss back into account 88888, confident that if he'd got outta the previous one, he could do it again. He began making risky trades to try to recover that initial loss, and as the losses mounted in the five eights account, it became harder and harder to make new trades to cover the last loss. By the end of 1993, his losses exceeded $30 million. Leeson is obviously an extreme example, but this tendency to overestimate our abilities is something we all share. So, the question is why? - The obvious explanation that a lot of people default to that is we wanna feel good about ourselves and pretend like we're well-informed, that we enjoy enormous satisfaction from being able to say, "I know," or even better, "I told you so." And so, we pretend to ourselves and others that we know when we don't. That is the motivated egocentric version of an explanation for excessive faith in our own judgment. - [Narrator] Reichelt had faith than the idea, if nothing else. - But what if it's something more uncomfortable, stupidity? (lively retro music) Franz Reichelt was a tailor with no formal scientific or engineering training, but he was obsessed with solving the problem of aviation safety. He spent months designing a parachute suit, which repeatedly failed during testing, but he became convinced the issue was that he didn't have enough height for it to work. So, in February, 1912, he took it to the Eiffel Tower, and rather than using a dummy to test it, he jumped himself. Tragic, but also really dumb. (soft electro music) Do you recognize this graph? - The, like, Dunning-Kruger graph? - Are you confident that this is the actual Dunning-Kruger graph? - Not at all, in fact, I think that this is not the Dunning-Kruger graph. I think that this is a bit of a communication trick. - This is what people call the Mount Stupid Curve, which will pop up if you search for the Dunning-Kruger effect into Google images. - As far as I understand it, it's an effect that says that when you know very little about it, your confidence is high, and as you know more about it, your confidence sinks until you become a master at it. - But I think that the actual result is, like, a little bit more fuzzy than this. - It was. This graph doesn't actually show the Dunning-Kruger effect. It's just a meme that resonates with a lot of people, and it became conflated with the effect. In their original research, Dunning and Kruger tested people on tasks like grammar, logic and humor, and then they asked participants to estimate how well they performed. That produced this curve. You can see that those who performed worse had the largest mismatch between their confidence and performance. They were the most overconfident. Those who performed the best were actually slightly underconfident. This suggests that overconfidence may be linked to how much we know. Those who know less think that they know more than they do, but to me, this effect looks a little like a statistical artifact because while I was doing my PhD, I asked students some physics questions and I also asked for their confidence in their answers. And when I looked at the results, accuracy spanned the full range from nearly 0% to 100%, but confidence varied over a much narrower range. All the scores were roughly in the middle. This meant that poor performers were the most overconfident and the highest performers were actually slightly under confident. This is exactly what Dunning and Kruger found, so maybe overconfidence isn't entirely due to how much we know, but also because most of us express at least kind of middle-of-the-road confidence. But there is another factor at play here, which is how much information our brains are capable of processing. Monday, the 27th of January, 1986, it's 5:45 PM at the Kennedy Space Center in Cape Canaveral, and the engineers from Morton Thiokol, who made the Challenger space shuttle's rocket boosters make an emergency conference call. They've just seen the weather forecast, predicting temperatures overnight will plummet to 25 degrees Fahrenheit, far colder than any previous shuttle launch. They know the rubber O-rings that seal joints in the boosters become less flexible in the cold, but have just a few hours to gather data, create charts, and present their case. Over the next six hours, the engineers present 13 charts with data on O-ring temperature, hot gas erosion, joint rotation, and more. But the data is scattered, incomplete, and not synthesized into a clear narrative. They'd never tested below 53 degrees Fahrenheit, so NASA managers were trying simultaneously to track historical O-ring data, erosion patterns, joint dynamics, seal resiliency, pressure differentials, and more. No single chart told the whole story. So, overwhelmed by seemingly contradictory data and confident that their rocket boosters were safe, Thiokol management overruled their own engineers and approved the launch. (fire roars) At 11:38 the next morning, 73 seconds after launch, (explosion booms) all seven crew members were killed. (chiming mysterious music) - Calibrating your certainty requires thinking of all the ways that you could be wrong, and that's hard for finite, fallible agents like us if it means considering everything that we don't know. - How many chunks of novel information you can hold in your head at one time is your short-term memory capacity. In 2008, Hansson, Juslin, and Windmann investigated how short-term memory capacity was linked to accuracy and overconfidence. Participants were asked to give ranges for factual questions like the length of a river or the population of a city. People's ranges were consistently too narrow, which effectively meant they were being overconfident, and those who had worse short-term memory were more often wrong and more likely to be overconfident. Another study conducted by Conte in 2023 asked participants to keep sequences of letters in their mind while they judged their own performance. As the memory load increased, confidence estimates became less accurate, even for participants with higher working memory capacities. Together, these studies suggest that assessing your accuracy is a mentally taxing task. So, overconfidence isn't necessarily about arrogance. It's your brain working at the limits of what it can track and hold. And because of this, your brain can start using shortcuts. Psychologist Daniel Kahneman describes these mental shortcuts as heuristics, that together, create systemic errors called cognitive biases. One shortcut we use a lot is substituting hard questions with easier related ones. Researchers have tested this by asking students how happy they were in their life and how many dates they'd had in the last month. Unsurprisingly, these two questions did not correlate. There's a lot more to happiness than matches on Tinder, at least for most people. However, if you switch it around and ask about their dates first, suddenly, the correlation jumps to 0.66. Working out how happy you are in your life is a difficult question. You have to consider many things and balance them all out. So, when you're primed with the information about your dating life, you're very likely to substitute that hard question, how happy am I in my life, with, how many dates have I recently had? Overconfidence from misprocessing information like this can be disastrous. (low mysterious music) So, why are our brains wired this way? I mean, you might expect natural selection to have wiped out the confidently incorrect, but there is evidence that overconfidence can actually be advantageous. Overconfidence can massively improve your status. In a scientific version of "The Apprentice," scientists in 2012 compared participants' own assessments of their skill with objective measures. They placed them in group tasks to see who is chosen as a leader and whose ideas influenced the group, tracking status over multiple sessions and assessing whether the desire for status led participants to exaggerate their abilities. The results were clear, overconfident individuals were more likely to lead, assert themselves, and maintain influence, even when their actual abilities were mid. And the evidence certainly shows people react better to confident individuals. Using an fMRI, researchers at the University of Sussex measured brain activity of people after hearing unconfident versus confident advice, and those who listened to the confident advice had increased activity in the ventromedial prefrontal cortex. That's a brain region associated with processing rewards and expected satisfaction. This means that human brains are biologically tuned to be influenced by confident individuals. We literally feel better when we hear confident people. - But recognizing that dynamic highlights a potentially problematic incentive for anyone who's contending for positions that they want. People who express more confidence in employment interviews or political campaigns, for instance, do earn the confidence of interviewers and potential voters, even if they're being overconfident. They can't actually deliver. They don't actually know the answer, but they can talk a good line to impress others, even if they can't ultimately deliver on those grand assertions. They know the audience will place more faith in them, if they express... Well, they should express maximal confidence. - [Derek] Leeson knew this and he took advantage of it. While he was secretly racking up huge losses in the infamous five eights account, he was publicly posting huge profits and everyone believed the illusion. - They come in and they don't test any records, so I can't be happier. They didn't test one record. - [Derek] As Leeson's hidden losses mounted, he requested huge sums from head office to keep doubling down up to $5 million at a time. Barings management, barely understanding futures and believing in their star trader, they granted his requests and continued to grant future requests. - Every day that I make one of these requests for additional money, I never expect it to come. I expect somebody to say, "Look, mate, what the hell's going on?" - By Autumn 1994, the account was nearly $260 million in the red. To mask this, Leeson began buying futures from himself, inflating his perceived profits further. At SIMEX's 10th anniversary in September, Barings received two awards, largely credited to Leeson. In December, he was flown to New York, seemingly responsible for $44 million in Barings turnover that year. Some traders raised doubts that these kinds of profits could be made from the low risk trading he was supposed to be doing. But management's faith in Leeson's talent was unshakeable, and they dismissed these concerns. Barings' overconfidence in Leeson and Leeson's overconfidence in himself would be the bank's downfall. The figures are so big, it seems like the ultimate confidence trick, but there's a partial explanation for the delusion on both sides. Leeson's and Barings' overconfidence was amplified by the complexity and unpredictability of the market and the trades he was making. It's sort of an issue of feedback. In a controlled environment where there are clear rules and guaranteed outcomes like in a chess match, there is clear feedback on whether decisions are good or bad. With reliable feedback, professional chess players are able to learn to make better decisions with more accurate confidence. But in a noisy environment where there is rarely consistent or timely consequences for predictions, this feedback is unreliable. Whether our confidence is accurate or misplaced is increasingly hard to judge, even amongst experts. It's especially problematic for political pundits. - This is going to be a landslide. I think Romney's gonna win by quite a bit. - So, right now, we have Hillary's about a 75 or an 80% favorite. - [Derek] For example, prior to 2024, political analyst Allan Lichtman had accurately predicted the winner of nine of the 10 previous US presidential elections, using his 13 keys to the White House method. Using the same strategy in 2024, he predicted that- - Kamala Harris will be a precedent-breaking president. - And look what happened. Is this crazy? (crowd cheering) - He attributed his miscalculation to the spread of disinformation that misled the electorate. This noisy environment made it difficult to discern key issues like the actual state of the economy. Similarly, the feedback Leeson had received was inconsistent. He was making some bad trades, but he had also won it all back before, and this significantly clouded his judgment, amplifying his overconfidence. By 1995, Leeson's losses were in the hundreds of millions, and Barings had unwittingly sent him $1 billion. For a bank with around $700 million in capital base, they were legally only allowed to lend around a quarter of that, but no one questioned it. They were all blinded by his apparent success. At this point, his positions were so big, he estimates that he was probably half of the entire Nikkei futures market, so all he could do was buy himself some time and hope that the market went his way. And for a while, it worked. The economy was stable and he couldn't see anything on the horizon that would change this. But then disaster struck. - [Reporter] Japan is tonight in a state of mourning and of shock. (siren wailing) - On the 17th of January, 1995, the Great Hanshin Earthquake struck Japan 20 kilometers from the city of Kobe. With the magnitude of 6.9, it devastated the city, which was one of Japan's key ports. This devastation spread to the stock market. The Nikkei index plunged 1055 points. Leeson, attempting to double down again, risked even more money. He bet heavily that the Nikkei would make a rapid recovery, but it didn't. And in the end, in today's money, Leeson had lost $2.8 billion. On the 23rd of February, Leeson went on the run. And three days later, Barings, one of the oldest and most trusted banks in the world, collapsed. Overconfidence was at least partially to blame for its downfall. Realizing the walls were closing in, Leeson fled to Malaysia and then Thailand, but his escape was short-lived. He was eventually arrested in Germany and extradited to face justice, marking the end of a spectacularly destructive gamble. He was just 28 years old. Now, we don't all bring down banks, but we are all vulnerable to overconfidence. In a complex world with unclear, noisy feedback where our brains are overwhelmed, a set of simplistic biases can take over. And we all too often end up thinking we know more than we do. So, what can we actually do about this? - I try to get better at calibrating my confidence judgments by keeping track and keeping score. So, when a colleague asks me, "How long is it going to take you to get me comments on this paper draft we're working on?" I don't promise I'll do it by Friday. I'm much more likely to say something like, "I think there's a 60% chance I can get you comments by Friday." They'll often react with a quizzical look or a laugh. - Well, practicing and being aware of our calibration is the obvious way to improve, but so is being intellectually humble. - I think that the best medicine for overconfidence is not so much information as feedback, (chuckles) and I get plenty of that. (laughs) (Derek laughs) Though also, I think people are right, that sometimes I do have a little bit of overconfidence. - If we wanna become more accurate, we should capitalize on the wisdom of the crowd by listening more to others. In particular, we should listen to people who disagree with us. Understanding the best arguments of your critics, understanding what information those who disagree with you have that you lack is very helpful for making better decisions. - The best calibrated people aren't those who know the most. It's those who know what they don't know. So, true wisdom lies not in being certain, but in knowing the limits of your own certainty. And that's an idea that's inspired our latest project. All those questions I asked- - These are good questions. (laughs) - Aw! (Hannah laughs) - They come from a new board game that we've made. It's called "Elements of Truth." The game contains over 800 fascinating science trivia questions with a twist. The number of points you win on each question depends on how confident you are. You can bid any number from 1 to 10. If you're not sure, you can play a low number or you can try to follow the lead of someone else who you think should know the answer. We've tested this game with scientists, teachers, and students, and what we've found is that it regularly leads to discussions that go way beyond the initial questions. The core game comes with 200 questions that cover all aspects of science, and there are five additional packs on specific topics like physics, technology, engineering, and astronomy. Plus, there's a Veritasium pack on concepts covered in many of our most popular videos. We're launching the game through Kickstarter to give you the opportunity to shape it with us. Over the next month, you'll be able to submit questions for a special community pack. This is your chance to etch your name into Veritasium history with a credited question in the game. To reserve your copy and get involved, use this QR code or the link in the description to head over to Kickstarter. It is only because of you that I've been able to make this channel and this game, so as always, I wanna thank you for your support and thank you for watching.